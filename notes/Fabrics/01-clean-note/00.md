# Microsoft Fabric â€“ Personal Study Notes

## Image-001: Microsoft Fabric Overview

![Image-001](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/he3brmwuyr6mcuact98f.png)

### Fabric Components

* **Data Factory** â€“ Azure Data Factory
* **DE** â€“ Data Engineering
* **DW** â€“ Data Warehouse
* **Data Science**
* **Real-Time Intelligence (REAL TIME INT)**
* **DB** â€“ Database

### Key Understanding

* Microsoft Fabric is a **single analytics platform** inside Azure
* We **do not need to switch platforms**
* We **do not need to worry about**:

  * Integrations
  * Networking
  * Tool compatibility
* **Power BI (PBI)** is part of the **Azure cloud family**
* **Fabric** is also part of the **Azure ecosystem**

ðŸ“Œ *Image-001 shows the complete overview of Fabric and its unified services.*

---

## Image-002: Organizational Tenant, Capacity & Workspace

![Image-002](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/hm48jxf93ws272el1zog.png)

---

## Organizational Tenant

* The **first layer** in Fabric is the **Organizational Tenant**
* When we create an **Azure account using our email**, it represents an **organization**
* The tenant contains **everything** related to that organization

---

## Azure vs Fabric

* In **Azure**, we create **resources**
* In **Fabric**, we create **similar resources**, but **capacity is mandatory**

---

## Capacity (Core Fabric Concept)

* **Capacity** is a **bundle of resources**
* Includes:

  * Compute
  * RAM
  * Storage
* Capacity decides the **computation power** of Fabric workloads
* Multiple capacities can be created for **multiple purposes**

### Example

A business with three branches:

* **USA** â†’ F-32 capacity
* **UK** â†’ F-16 capacity
* **Germany** â†’ Capacity based on requirement

ðŸ“Œ Capacity helps in performance management and workload isolation.

---

## Workspace

* **Workspace** is similar to an **Azure Resource Group**
* Can be understood as:

  * Folder
  * Container
* Multiple **workspaces** can exist under **one capacity**

ðŸ“˜ Reference: *Microsoft Learn â€“ Microsoft Fabric Licensing*

---

## Account Creation

* Fabric account created
* Time taken: **43 minutes**

---

## OneLake â€“ OneDrive for Data

![One Lake One drive for Data](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/h6lhfdzfgr0x3ap3vwiv.png)

---

## What is OneLake?

* OneLake is **OneDrive for Data**
* Just like OneDrive stores:

  * Images
  * Files
  * Videos
* OneLake stores **all analytics data**

---

## OneLake Storage Technology

* OneLake is built on **ADLS Gen2 (Azure Data Lake Storage Gen2)**

---

## Data Types Supported in OneLake

* **Structured data**
* **Semi-structured data**
* **Unstructured data**

### Examples

* Semi-structured â†’ CSV
* Unstructured â†’ Images
* Structured â†’ Tables

---

## Parquet Format (Important)

* **Parquet** is a **columnar storage format**
* Optimized for:

  * Analytics workloads
  * Large-scale data processing
* Benefits:

  * Faster read performance
  * Reads only required columns
  * Better compression

ðŸ“Œ Fabric internally relies on **Parquet for analytics efficiency**

---

## Delta Parquet Format (Very Important)

### What is Delta Parquet?

* **Delta Parquet = Parquet + Transaction Log**
* Used by Fabric to store **structured data** in OneLake

### Why Fabric Uses Delta Parquet

Delta Parquet provides:

* **ACID Transactions**
* **Schema Enforcement**
* **Schema Evolution**
* **Time Travel**
* Reliable **UPDATE, DELETE, MERGE**

ðŸ“Œ Plain Parquet does not support these features.

---

## How Fabric Stores Data in OneLake

* **Structured data** â†’ Stored automatically in **Delta Parquet format**
* **Semi-structured data** â†’ Stored as files (CSV, JSON)
* **Unstructured data** â†’ Stored as files (Images, videos)

ðŸ‘‰ Fabric handles this automatically. No manual storage management needed.

---

## Cloud Storage Comparison

* **Azure** â†’ ADLS Gen2
* **AWS** â†’ S3
* **GCP** â†’ Google Cloud Storage

---

## Why Do We Need OneLake When Azure Already Has Storage?

### Problem Before OneLake

* Separate storage accounts for:

  * Streaming data
  * Flat files
  * Logs
  * Analytics
* As services increase, **storage accounts increase**
* Causes:

  * Maintenance overhead
  * Integration complexity
  * Connectivity issues

---

## OneLake Solution

* Microsoft Fabric introduced **OneLake**
* Provides:

  * Single unified storage
  * No multiple storage accounts
  * No networking or integration worries

ðŸ“Œ Thatâ€™s why OneLake is called a **Logical Data Lake**

---

## Workspace & OneLake Mapping

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/w5xplgars5vik7yttyio.png)

### Explanation

* Each **workspace** appears as a **container** in OneLake
* Data items appear as **folders** inside the workspace container

---

## Parquet Format & Delta Parquet Format (Very Important for Fabric)

### What is Parquet Format?

* **Parquet** is a **columnar storage file format**
* Used mainly for **analytics workloads**
* Optimized for:

  * High performance
  * Large-scale data processing
  * Low storage cost

### Why Columnar Format?

* Data is stored **column by column**, not row by row
* Helps in:

  * Faster read performance
  * Reading only required columns
  * Better compression

ðŸ“Œ **Fabric uses Parquet internally for analytics efficiency**

---

## Delta Parquet Format (Delta Lake)

### What is Delta Parquet?

* **Delta Parquet = Parquet + Transaction Log**
* It is an **enhanced Parquet format**
* Used to manage **structured data** in OneLake

### Why Fabric Uses Delta Parquet?

Delta Parquet provides:

* **ACID Transactions**

  * Atomicity
  * Consistency
  * Isolation
  * Durability
* **Schema Enforcement**
* **Schema Evolution**
* **Time Travel**

  * Query historical versions of data
* **Reliable updates, deletes, and merges**

ðŸ“Œ This solves problems that **plain Parquet cannot handle**.

---

## How Fabric Stores Data in OneLake

* **Structured data**

  * Automatically stored in **Delta Parquet format**
* **Semi-structured data**

  * Stored as files (CSV, JSON, etc.)
* **Unstructured data**

  * Stored as files (Images, videos, text)

ðŸ‘‰ As a Fabric user, **you do not need to manually manage this**.
Fabric handles it **automatically**.

---

## Why Delta Parquet is Critical in Fabric Learning

Without Delta Parquet:

* No reliable updates
* No data versioning
* No transactional consistency

With Delta Parquet:

* Data Engineering becomes easier
* Data Warehouse workloads are reliable
* Data Science experiments are reproducible

ðŸ“Œ This is one of the **core reasons Fabric can unify DE, DW, and BI** on OneLake.

---

## Exam / Interview Memory Tip

> **OneLake stores structured data in Delta Parquet format to support ACID transactions, schema evolution, and time travel across Fabric workloads.**

---

